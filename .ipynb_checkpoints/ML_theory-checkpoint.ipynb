{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158d34f6",
   "metadata": {},
   "source": [
    "**General Machine Learning Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50d5c7",
   "metadata": {},
   "source": [
    "**Machine learning = science of programming computers so they can learn from data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed38ab7",
   "metadata": {},
   "source": [
    "# Statistical learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d127b",
   "metadata": {},
   "source": [
    "**Statistical learning = a set of approaches for estimating f.**\n",
    "\n",
    "$$\\large Y = f(X) + \\epsilon$$ \n",
    "\n",
    "where $\\epsilon$ is a random error term which is independent of X and has mean zero, f represents the systematic information that X provides about Y.\n",
    "\n",
    "**X:** input variables (predictors/ features/ independent variables)\n",
    "\n",
    "**Y:** output variable (response/ dependent variable)\n",
    "\n",
    "Main reasons for estimating f?\n",
    "- **Prediction**: \n",
    "\n",
    "    - When a set of inputs X is readily available, but the output Y can not easily be obtained. \n",
    "    - Since $\\epsilon$ averages to zero, Y is predicted using:\n",
    "\n",
    "    $ \\hat{Y} = \\hat{f}(X) $, where $\\hat{f}$ is the estimate for $f$ and $\\hat{Y}$ is the resulting prediction. \n",
    "    - Here, we are not concerned with the exact form of $\\hat{f}$ (it's a black box).\n",
    "    - There are two types of errors: \n",
    "        - **the reducible error** ($\\hat{f}$ is not a perfect estimate of $\\hat{f}$) \n",
    "        - **the irreducible error** (the existence of $\\epsilon$ > 0), this error provides an upper bound on the accuracy of our predictions for Y.\n",
    "\n",
    "\n",
    "- **Inference**:\n",
    "    - When trying to understand the association between $Y$ and $X_{1}, X_{2}, X_{3}, ...$\n",
    "    \n",
    "There are two types of statistical learning methods:\n",
    "\n",
    "- **Parametric**: It reduces the problem of estimating $f$ down to one of estimating a set of\n",
    "parameters. How? First you make an assumption about the function form (i.e. it is linear), then you fit (or train) the chosen model (i.e. with the ordinary least squares method).\n",
    "\n",
    "\n",
    "- **Non-parametric**: do not make explicit assumptions about the functional form of $f$. Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly. Disadvantage: since they do not reduce the problem of estimating $f$ to a small number of parameters, a very large number of observations (far more than is typically needed for a parametric approach) is required in order to obtain an accurate estimate for $f$.\n",
    "\n",
    "Difference between Regression and Classification problems:\n",
    "\n",
    "- **Regressions** require a quantitative response.\n",
    "- **Classifications** require a qualitative response (logistic regression falls into this category!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830331a5",
   "metadata": {},
   "source": [
    "## Model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3e80c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9e7bf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For regressions, the most commonly used quality of fit method is the mean squared error (MSE). \n",
    "\n",
    "$$\\large MSE = \\frac{1}{n} \\sum\\limits_{i=1}^n (y_{i} - \\hat{f}(x_{i}))^2$$\n",
    "\n",
    "Here, the MSE is computed using the training data, so it is referred to the training MSE. Since we are interested in the accuracy of the predictions we should instead compute the test MSE (the average squared prediction error for these test observations $(x_{0}, y_{0})$):\n",
    "\n",
    "$$\\large Ave (y_{0} - \\hat{f}(x_{0}))^2$$\n",
    "\n",
    "Obs: there is no guarantee that the method with the lowest training MSE will also have the lowest test MSE!\n",
    "\n",
    "The expected test MSE for a given value $x_{0}$ can always be decomposed into the sum of three fundamental quantities: the variance of $\\hat{f}(x_{0})$, the squared bias of $\\hat{f}(x_{0})$, and the variance of the error term $\\epsilon$. \n",
    "\n",
    "   Since both the $Var(\\hat{f}(x_{0}))$ and the $Bias(\\hat{f}(x_{0}))^2$ are both non negative terms, the expected test MSE can never lie below $Var(\\epsilon)$\n",
    "    \n",
    "   **BIAS-VARIANCE TRADE-OFF**\n",
    "   - **The variance = amount by which $\\hat{f}(x_{0})$ would change if we estimated it using a different training data set.**\n",
    "   - **Bias = error that is introduced by approximating a real life problem by a much simpler model.**\n",
    "   - In general, the more flexible the model, the higher the variance and the lower the bias. The bias tends to initially decrease more than the variance increases. That is why the test MSE usually decreases at first (until the variance starts to significantly increase)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146fd48",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278264f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The **bias-variance trade-off** transfers over to the classification setting. However, since $y_{i}$ is no longer quantitative, the accuracy of the estimate $\\hat{f}(x_{0})$ is given by the training error rate:\n",
    "\n",
    "$$\\large \\frac{1}{n} \\sum\\limits_{i=1}^n I(y_{i} \\neq \\hat{y_{i}})$$\n",
    "\n",
    "where $\\hat{y_{i}}$ is the predicted class label for the ith observation and $I(y_{i} \\neq \\hat{y_{i}})$ is an indicator variable that equals 1 if $y_{i} \\neq \\hat{y_{i}}$, and 0 if $y_{i} = \\hat{y_{i}}$.\n",
    "\n",
    "The test error rate is:\n",
    "\n",
    "$$\\large Ave(I(y_{0} \\neq \\hat{y_{0}})$$\n",
    "\n",
    "where $y_{0}$ is the predicted class label that results from applying the classifier to the test observation with predictor $x_{0}$.\n",
    "\n",
    "This test error is minimized on average by **the Bayes Classifier** which assigns each observation to the most likely class, given its predictor values. The classifier always chooses the class for which $P(Y=j | x=x_{0})$ is the largest.\n",
    "\n",
    "The Bayes classifier produces the lowest possible test error rate. The Bayes error rate is:\n",
    "\n",
    "$$\\large 1 - E(max_j P(Y = j | X))$$\n",
    "\n",
    "In practice, you can't calculate the conditional distribution of Y given X because that distribution is defined over the entire population. The Bayes Classifier is the state of nature that we do not know but we aim to approximate as well as possible.\n",
    "Another method that attempts to estimate the conditional distribution of Y given X, and then classifies a\n",
    "given observation to the class with highest estimated probability is **the KNN Classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a515dbc",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955bd310",
   "metadata": {},
   "source": [
    "In the absence of a very large designated test set that can be used to directly estimate the test error rate, a number of techniques can be used to estimate this quantity using the available training data. \n",
    "\n",
    "- **Validation set approach:**\n",
    "\n",
    "Method: randomly dividing the available set of observations into two parts, a **training set** and a **validation set or hold-out set**. The model is fit on the training set, and the fitted model is used to predict the\n",
    "responses for the observations in the validation set. The resulting validation set error rate provides an estimate of the test error rate.\n",
    "\n",
    "Drawbacks:\n",
    "1. Highly variable validation estimate of the test error rate (depending on which observations are included in the training/validation sets).\n",
    "2. Only a subset of the observations (those that are included in the training set) are used to fit the model. The validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set.\n",
    "\n",
    "- **Leave one out approach:**\n",
    "\n",
    "- **K-fold cross validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878f250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
