{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa69123e",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9458e",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6a774",
   "metadata": {},
   "source": [
    "Decision trees involve segmenting the predictor space into a number of distinct and non-overlapping regions (R1, R2, ... RJ). Each split of the domain is aligned with one of the feature axes (in theory they could have any shape but \"rectangles\" are chosen for simplicity's sake and ease of interpretation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c651c0",
   "metadata": {},
   "source": [
    "### Regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34032c1",
   "metadata": {},
   "source": [
    "In Summary:\n",
    "- Any new observation that falls into a particular partition RJ has the estimated response given by the MEAN of all training observations in RJ.\n",
    "- The goal is to find boxes that minimize **the Residual Sum of Squares (RSS)**.\n",
    "- Since it is computationally expensive to consider all possible partitions of the feature space into J rectangles, minimizing the RSS is done with **the Recursive Binary Splitting approach (RBS)**.\n",
    "- In one sentence: the RBS approach helps construct a tree by considering all features (X1, ... Xp) and all possible values of the cutpoint s for each of the features, and then choosing at each node feature that best splits the data. It is said to be: \n",
    "    - *top down* because it begins at the top of the tree (at which point all observations belong to a single region) and then successively splits the predictor space (each split --> new branch). \n",
    "    - *greedy* because at each step of the building process, the best split is made at that particular step, rather than looking ahead and picking a split that will lead to a better tree in some future step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93706b4d",
   "metadata": {},
   "source": [
    "$ \\large RSS = \\sum\\limits_{j=1} ^{J} \\sum\\limits_{i \\in R_{j}} (y_{i} - y_{R_{J}})^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d6fef",
   "metadata": {},
   "source": [
    "### Classification trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3516c",
   "metadata": {},
   "source": [
    "Any new observation that falls into a particular partition RJ has the estimated response given by the MODE of all training observations in RJ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b9acc",
   "metadata": {},
   "source": [
    "### Good links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd3373",
   "metadata": {},
   "source": [
    "https://www.quantstart.com/articles/Beginners-Guide-to-Decision-Trees-for-Supervised-Machine-Learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ea8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
